{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble-classifier-combination-tester.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgd5T3WbFCpDMQ307V5wd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acevedosharp/ensemble-testing-chamber/blob/master/ensemble_classifier_combination_tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VVkWfGqHHs6"
      },
      "source": [
        "- assemble all possible combination of ensembles $k \\in \\{1,2,3,4,5\\}$\r\n",
        "- 10-fold cross validation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOTCnQy8CnV0"
      },
      "source": [
        "import itertools\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ORrJknmQBF"
      },
      "source": [
        "classifiers = {\r\n",
        "    \"Linear SVC\":sklearn.svm.LinearSVC(),\r\n",
        "    \"Decission Tree\": sklearn.tree.DecisionTreeClassifier(),\r\n",
        "    \"Extra Tree\": sklearn.tree.ExtraTreeClassifier(),\r\n",
        "    \"Logistic\": sklearn.linear_model.LogisticRegression(),\r\n",
        "    \"Passive Aggressive\": sklearn.linear_model.PassiveAggressiveClassifier(),\r\n",
        "    \"Perceptron\": sklearn.linear_model.Perceptron(),\r\n",
        "    \"Ridge\": sklearn.linear_model.RidgeClassifier(),\r\n",
        "    \"SGD\": sklearn.linear_model.SGDClassifier(),\r\n",
        "    \"Multi-layer Perceptron\": sklearn.neural_network.MLPClassifier(),\r\n",
        "    \"Linear Discriminant\": sklearn.discriminant_analysis.LinearDiscriminantAnalysis(),\r\n",
        "    \"Quadratic Discriminant\": sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis(),\r\n",
        "    \"BernoulliNB\": sklearn.naive_bayes.BernoulliNB(),\r\n",
        "    \"MultinomialNB\": sklearn.naive_bayes.MultinomialNB(),\r\n",
        "    \"Nearest Neighbors\": sklearn.neighbors.KNeighborsClassifier(),\r\n",
        "    \"Extra Trees\": sklearn.ensemble.ExtraTreesClassifier(),\r\n",
        "    \"Random Forest (10 estimators)\": sklearn.ensemble.RandomForestClassifier(n_estimators=10),\r\n",
        "    \"Gradient Boosting\": sklearn.ensemble.GradientBoostingClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "datasets = [\r\n",
        "            sklearn.datasets.load_digits(return_X_y=True),\r\n",
        "            sklearn.datasets.load_iris(return_X_y=True),\r\n",
        "            sklearn.datasets.load_wine(return_X_y=True),\r\n",
        "            sklearn.datasets.load_breast_cancer(return_X_y=True)\r\n",
        "]\r\n",
        "\r\n",
        "kf = KFold(n_splits=10)\r\n",
        "for ds_idx, ds in enumerate(datasets):\r\n",
        "  X, Y = ds[0], ds[1]\r\n",
        "  X = StandardScaler().fit_transform(X)\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index] # np.take\r\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index] # np.take\r\n",
        "\r\n",
        "    # Train every classifier with the new data\r\n",
        "    for classifier_name, classifier in classifiers.items():\r\n",
        "      classifier.fit(X_train, Y_train)\r\n",
        "      \r\n",
        "    # Assemble ensembles of size k in {1,2,3,4,5}\r\n",
        "    for k in range(1,5):\r\n",
        "      for combination in list(itertools.combinations(classifiers.keys(), k)):\r\n",
        "        ensemble = []\r\n",
        "\r\n",
        "        # group classifiers (already exist fitted in dict)\r\n",
        "        for idx in range(k)\r\n",
        "          ensemble.append(classifiers[combination[idx]])\r\n",
        "\r\n",
        "        # save predictions\r\n",
        "        predictions = np.zeros((len(X_test), k)) # (# test instances, ensemble size)\r\n",
        "        for idx, classifier in enumerate(ensemble):\r\n",
        "          predictions[:,idx] = classifier.predict(X_test)\r\n",
        "        \r\n",
        "        # do hard voting\r\n",
        "        hard_voting_predictions = np.zeros((len(X_test), 1)) # (# test instances, 1)\r\n",
        "        for idx in range(predictions.shape[0]):\r\n",
        "          values, counts = np.unique(predictions[idx], return_counts=True)\r\n",
        "          hard_voting_predictions[idx] = values[np.argmax(counts)]\r\n",
        "        \r\n",
        "        # compare voting predictions against Y_test\r\n",
        "        total_instance_number = len(X_test)\r\n",
        "        errors = 0\r\n",
        "        for idx in range(hard_voting_predictions.shape[0]):\r\n",
        "          if (hard_voting_predictions[idx][0] != Y_test[idx]):\r\n",
        "            errors += 1\r\n",
        "       \r\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}