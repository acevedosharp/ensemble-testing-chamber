{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble-classifier-combination-tester.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCf4v87cRQMRiFhdQj4+BC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acevedosharp/ensemble-testing-chamber/blob/master/ensemble_classifier_combination_tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5POcuMGvFbr"
      },
      "source": [
        "# Measuring the effectiveness of ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VVkWfGqHHs6"
      },
      "source": [
        "- assemble all possible combination of ensembles $k \\in \\{1,2,3,4,5\\}$\r\n",
        "- 10-fold cross validation\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCu4pVZQvAQq"
      },
      "source": [
        "## Experimental setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOTCnQy8CnV0"
      },
      "source": [
        "import itertools\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "# classifiers\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.tree import ExtraTreeClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "from sklearn.linear_model import RidgeClassifier\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "# datasets\r\n",
        "from sklearn.datasets import *\r\n",
        "\r\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOeNKRHjdcR8"
      },
      "source": [
        "ds_names = [\r\n",
        "            \"Breast Cancer\",\r\n",
        "            \"Digits\"\r\n",
        "]\r\n",
        "\r\n",
        "datasets = [\r\n",
        "            sklearn.datasets.load_breast_cancer(return_X_y=True),\r\n",
        "            sklearn.datasets.load_digits(return_X_y=True)\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY5YfKDUdeDw"
      },
      "source": [
        "ds_names = [\r\n",
        "            \"Iris\",\r\n",
        "            \"Wine\"\r\n",
        "]\r\n",
        "\r\n",
        "datasets = [\r\n",
        "            sklearn.datasets.load_iris(return_X_y=True),\r\n",
        "            sklearn.datasets.load_wine(return_X_y=True)\r\n",
        "]\r\n",
        "\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5YLMIyYkxk2"
      },
      "source": [
        "### Execute experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ORrJknmQBF",
        "outputId": "51dfd614-963a-4ef6-df0c-201116f94bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifiers = {\r\n",
        "    \"Linear SVC\": LinearSVC(),\r\n",
        "    \"Decission Tree\": DecisionTreeClassifier(),\r\n",
        "    \"Extra Tree\": ExtraTreeClassifier(),\r\n",
        "    \"Logistic\": LogisticRegression(),\r\n",
        "    \"Passive Aggressive\": PassiveAggressiveClassifier(),\r\n",
        "    \"Perceptron\": Perceptron(),\r\n",
        "    \"Ridge\": RidgeClassifier(),\r\n",
        "    \"SGD\": SGDClassifier(),\r\n",
        "    \"Multi-layer Perceptron\": MLPClassifier(),\r\n",
        "    \"Linear Discriminant\": LinearDiscriminantAnalysis(),\r\n",
        "    \"Quadratic Discriminant\": QuadraticDiscriminantAnalysis(),\r\n",
        "    \"BernoulliNB\": BernoulliNB(),\r\n",
        "    \"MultinomialNB\": MultinomialNB(),\r\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(),\r\n",
        "    \"Extra Trees\": ExtraTreesClassifier(),\r\n",
        "    \"Random Forest (10 estimators)\": RandomForestClassifier(n_estimators=10),\r\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "results = []\r\n",
        "\r\n",
        "kf = KFold(n_splits=10)\r\n",
        "for ds_idx, ds in enumerate(datasets):\r\n",
        "  X, Y = ds[0], ds[1]\r\n",
        "  #X = StandardScaler().fit_transform(X)\r\n",
        "  fold_index = 0\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index] # np.take\r\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index] # np.take\r\n",
        "\r\n",
        "    # Train every classifier with the new data\r\n",
        "    for classifier_name, classifier in classifiers.items():\r\n",
        "      classifier.fit(X_train, Y_train)\r\n",
        "    # Assemble ensembles of size k in {1,2,3,4,5}\r\n",
        "    for k in range(1,6):\r\n",
        "      for combination in list(itertools.combinations(classifiers.keys(), k)):\r\n",
        "        ensemble = []\r\n",
        "        ensemble_description = \"\"\r\n",
        "\r\n",
        "        # group classifiers (already exist fitted in dict)\r\n",
        "        for idx in range(k):\r\n",
        "          ensemble.append(classifiers[combination[idx]])\r\n",
        "          ensemble_description += combination[idx]\r\n",
        "          ensemble_description += \"-\"\r\n",
        "        ensemble_description = ensemble_description[:-1]\r\n",
        "\r\n",
        "        # save predictions\r\n",
        "        predictions = np.zeros((len(X_test), k)) # (# test instances, ensemble size)\r\n",
        "        for idx, classifier in enumerate(ensemble):\r\n",
        "          predictions[:,idx] = classifier.predict(X_test)\r\n",
        "        \r\n",
        "        # do hard voting\r\n",
        "        hard_voting_predictions = np.zeros((len(X_test), 1)) # (# test instances, 1)\r\n",
        "        for idx in range(predictions.shape[0]):\r\n",
        "          values, counts = np.unique(predictions[idx], return_counts=True)\r\n",
        "          hard_voting_predictions[idx] = values[np.argmax(counts)]\r\n",
        "        \r\n",
        "        # compare voting predictions against Y_test\r\n",
        "        total_instance_number = len(X_test)\r\n",
        "        errors = 0\r\n",
        "        for idx in range(hard_voting_predictions.shape[0]):\r\n",
        "          if (hard_voting_predictions[idx][0] != Y_test[idx]):\r\n",
        "            errors += 1\r\n",
        "        score = errors/total_instance_number\r\n",
        "\r\n",
        "        # save result (ensemble description, ensemble size, fold index, dataset, score)\r\n",
        "        results.append([ensemble_description, k, fold_index, ds_names[ds_idx], score])\r\n",
        "\r\n",
        "    fold_index += 1\r\n",
        "        "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1w2RGxk1lc"
      },
      "source": [
        "## Analysing results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scSXWuWTlEVx"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vVQX6L1lKVd"
      },
      "source": [
        "def saveResultsAsCsv(filename, headers, rows):\r\n",
        "  if len(headers) == len(rows[0]):\r\n",
        "    with open(filename,'w') as file:\r\n",
        "      file.write(','.join(headers))\r\n",
        "      file.write('\\n')\r\n",
        "      for row in final_results:\r\n",
        "        file.write(','.join(list(map(lambda rc: str(rc), row))))\r\n",
        "        file.write('\\n')\r\n",
        "  else:\r\n",
        "    raise Exception('length of headers does not match length of single rows.')\r\n",
        "\r\n",
        "def filterFinalResultsByDataset(datasetName):\r\n",
        "  return list(filter(lambda res: str(res[2]) == datasetName, final_results))\r\n",
        "\r\n",
        "def loadResultsFromCsv(filename):\r\n",
        "  loadedResults = []\r\n",
        "  with open(filename) as file:\r\n",
        "    loadedResults = list(map(lambda entry: entry.split(','), [x.strip() for x in file.readlines()]))\r\n",
        "  file.close()\r\n",
        "  print('Headers are:', loadedResults[0])\r\n",
        "  del loadedResults[0]\r\n",
        "  return loadedResults\r\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFYgGR4blnTo"
      },
      "source": [
        "### Aggregate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBZs0JFQbbft"
      },
      "source": [
        "unique_ensembles = []\r\n",
        "final_results = []\r\n",
        "\r\n",
        "for ensemble in list(map(lambda res: res[0], results)):\r\n",
        "  if ensemble not in unique_ensembles:\r\n",
        "    unique_ensembles.append(ensemble)\r\n",
        "\r\n",
        "for i, ensemble_description in enumerate(unique_ensembles):\r\n",
        "  filtered = list(filter(lambda res: str(res[0]) == ensemble_description, results))\r\n",
        "  sum = 0\r\n",
        "  for entry in filtered:\r\n",
        "    sum += float(entry[4])\r\n",
        "  mean_error = sum / 10\r\n",
        "  final_results.append([filtered[0][0], filtered[0][1], filtered[0][3], mean_error]) # [ensemble_description, ensemble_size, dataset, mean_error]\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSMHbcE-rJRd"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rikxkjMrOFX"
      },
      "source": [
        "saveResultsAsCsv('finalResultsIris-Wine.csv', ['ensembleDescription', 'k', 'dataset', 'errorRate'], final_results)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nL_M4UJqSog"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkUHqB1yv0XT"
      },
      "source": [
        "# join two results, create a modifier cell to evaluate metrics for a particular dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17hLSwlgqcQw"
      },
      "source": [
        "#### Mean error rate for ensembles of size <k>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67NTipV-fuBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d4900b-9b84-43ab-e6ea-ba05aebe4cb9"
      },
      "source": [
        "meanErrorRateSizeK = {}\r\n",
        "\r\n",
        "for k in range(1,6):\r\n",
        "  sum = 0\r\n",
        "  ensembles_k = list(filter(lambda res: int(res[1]) == k, final_results))\r\n",
        "  for res in ensembles_k:\r\n",
        "    sum += float(res[3])\r\n",
        "  errorRate = sum/len(ensembles_k)\r\n",
        "  print(f\"Mean error rate in ensembles of size {k}: {errorRate}\")\r\n",
        "  meanErrorRateSizeK[k] = errorRate"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean error rate in ensembles of size 1: 0.45599769319492506\n",
            "Mean error rate in ensembles of size 2: 0.48339484813533246\n",
            "Mean error rate in ensembles of size 3: 0.2864331987697039\n",
            "Mean error rate in ensembles of size 4: 0.24967328500027436\n",
            "Mean error rate in ensembles of size 5: 0.19845510602430919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--KHaeYhq5lm"
      },
      "source": [
        "#### For every classifier, the errorRates of ensembles of different <k>s that contained it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsuQjvs9gYOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "7ffbc714-ff43-43fb-bb2d-33915c39c7f9"
      },
      "source": [
        "# Mean error rate of ensembles of size <k> that contained <classifier>\r\n",
        "for ensemble in unique_ensembles:\r\n",
        "  for k in range(1,6):\r\n",
        "    sum = 0\r\n",
        "    ensembles_k_unique = list(filter(lambda res: (int(res[1]) == k) and (str(res[0]) == ensemble, final_results)))\r\n",
        "    for res in ensembles_k:\r\n",
        "      sum += float(res[3])\r\n",
        "    print(f\"Mean error rate in ensembles of size {k} that contained {ensemble}: {sum/len(ensembles_k)}\")\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6e26b2ba1962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mensembles_k_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensembles_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: filter expected 2 arguments, got 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSbgZxPfrkht"
      },
      "source": [
        "#### Distribution of size k of ensembles with an errorRate < \\<errorRate\\>"
      ]
    }
  ]
}